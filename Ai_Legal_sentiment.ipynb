{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e784ae8"
      },
      "source": [
        "# Task\n",
        "Modify the code to allow the user to upload a CSV dataset, perform sentiment analysis on the 'Text' column, and save the results to a new CSV file named \"predicted_output.csv\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf88b95b"
      },
      "source": [
        "## Add file upload functionality\n",
        "\n",
        "### Subtask:\n",
        "Add code to the notebook to prompt the user to upload a CSV file and get the path to the uploaded file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18b0016f"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary module and use it to prompt the user for a file upload, then store the path of the uploaded file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "d56da8b8",
        "outputId": "7f22436a-1604-43f0-9be8-774d0237e597"
      },
      "source": [
        "!pip install transformers torch pandas\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "uploaded_file_path = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded file: {uploaded_file_path}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0ff72205-5641-43df-aebf-dae26905054c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0ff72205-5641-43df-aebf-dae26905054c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving custom_legal_dataset (1).csv to custom_legal_dataset (1).csv\n",
            "Uploaded file: custom_legal_dataset (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48d22062"
      },
      "source": [
        "## Modify data loading to use the uploaded file\n",
        "\n",
        "### Subtask:\n",
        "Update the data loading part of the code in cell `UNYkNccLZJU_` to read the CSV file uploaded by the user.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32de35ab"
      },
      "source": [
        "**Reasoning**:\n",
        "Modify the code to use the uploaded file path for reading the CSV data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b245e91b"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because `pd` and `sys` were not defined. I need to import `pandas` as `pd` and the `sys` module. I also need to import `os` which is used later in the code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99fb7090"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback indicates that `AutoTokenizer` and `AutoModelForSeq2SeqLM` were not imported. I need to add the import statement for these classes from the `transformers` library. The previous cell already imported `pandas`, `sys`, and `os`, so I don't need to repeat those imports.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6b14f01b"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback shows that `args` is not defined. The original code used `args` to specify the output file path. Since I am modifying the code to use the uploaded file and hardcode the output file name, I need to define a variable for the output file path.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DM1IWYjm7b10",
        "outputId": "3c233c1b-233c-46f8-cc47-de925037b382"
      },
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "# Load and process data\n",
        "try:\n",
        "    # The uploaded_file_path is available from the previous cell\n",
        "    print(f\"Attempting to load {uploaded_file_path}\")\n",
        "    # Modify pd.read_csv to use the uploaded_file_path\n",
        "    data = pd.read_csv(uploaded_file_path, encoding='utf-8', on_bad_lines='warn')\n",
        "    print(f\"Raw columns detected: {data.columns.tolist()}\")\n",
        "    if data.empty:\n",
        "        raise ValueError(\"Input CSV is empty.\")\n",
        "\n",
        "    # Adjust if \"Text,Sentiment\" is a single column\n",
        "    if \"Text,Sentiment\" in data.columns and (\"Text\" not in data.columns or \"Sentiment\" not in data.columns):\n",
        "        print(\"Splitting 'Text,Sentiment' column...\")\n",
        "        data[[\"Text\", \"Sentiment\"]] = data[\"Text,Sentiment\"].str.split(\",\", n=1, expand=True)\n",
        "    elif \"Text\" not in data.columns or \"Sentiment\" not in data.columns:\n",
        "        raise ValueError(\"CSV must have 'Text' and 'Sentiment' columns or a 'Text,Sentiment' column to split.\")\n",
        "\n",
        "    data[\"Text\"] = data[\"Text\"].astype(str).str.strip().str.strip('\"')\n",
        "    data[\"Sentiment\"] = data[\"Sentiment\"].astype(str).str.strip().str.strip('\"')\n",
        "    texts = data[\"Text\"].tolist()\n",
        "    expected_sentiments = data[\"Sentiment\"].tolist()\n",
        "    print(f\"Loaded {len(texts)} rows from CSV: {texts[:5]}...\")  # Show first five for better debug\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or processing CSV: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Set up FLAN-T5 model\n",
        "try:\n",
        "    model_name = \"google/flan-t5-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda:0\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Sentiment classification function\n",
        "def get_sentiment(text):\n",
        "    print(f\"Processing text: {text[:100]}...\") # Print first 100 characters of text\n",
        "    prompt = f\"Classify the sentiment of this legal text as Positive, Negative, or Neutral. Examples: 'The case was resolved favorably.' → Positive, 'The contract terms are unfair.' → Negative, 'The summary is neutral.' → Neutral. Text: {text}\\nSentiment:\"\n",
        "    try:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(\"cuda:0\")\n",
        "        outputs = model.generate(**inputs, max_length=10, num_return_sequences=1)\n",
        "        sentiment = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        if \"Positive\" in sentiment:\n",
        "            return \"Positive\"\n",
        "        elif \"Negative\" in sentiment:\n",
        "            return \"Negative\"\n",
        "        elif \"Neutral\" in sentiment:\n",
        "            return \"Neutral\"\n",
        "        else:\n",
        "            return \"Neutral\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text '{text[:100]}...': {e}\") # Print error with truncated text\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "# Apply to all texts\n",
        "sentiments = [get_sentiment(text) for text in texts]\n",
        "\n",
        "# Create and save output\n",
        "output_df = pd.DataFrame({\"Statement\": texts, \"Predicted\": sentiments, \"Expected\": expected_sentiments})\n",
        "\n",
        "# Define the output file path\n",
        "output_csv_path = \"predicted_output.csv\"\n",
        "\n",
        "# Create the directory for the output CSV if it doesn't exist\n",
        "output_dir = os.path.dirname(output_csv_path)\n",
        "if output_dir and not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "try:\n",
        "    output_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Results saved to {output_csv_path}\")\n",
        "    # Display the output table\n",
        "    print(\"\\nSentiment Analysis Table:\")\n",
        "    print(output_df.to_string(index=False))\n",
        "    # Verify file creation\n",
        "    if os.path.exists(output_csv_path):\n",
        "        print(f\"Verified: Output file exists at {output_csv_path}\")\n",
        "    else:\n",
        "        print(f\"Warning: Output file was not created at {output_csv_path}\")\n",
        "except PermissionError:\n",
        "    print(f\"Error: Permission denied when saving to {output_csv_path}. Check directory permissions.\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving output: {e}\")\n",
        "    sys.exit(1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load custom_legal_dataset (1).csv\n",
            "Raw columns detected: ['Text', 'Sentiment']\n",
            "Loaded 25 rows from CSV: ['The court ruled in favor of the plaintiff, awarding full compensation.', 'The contract terms were deemed unfair and unenforceable by the judge.', 'The legal review concluded with no significant issues identified.', 'The attorney provided exceptional support during the trial.', 'The settlement negotiations broke down due to irreconcilable differences.']...\n",
            "Processing text: The court ruled in favor of the plaintiff, awarding full compensation....\n",
            "Processing text: The contract terms were deemed unfair and unenforceable by the judge....\n",
            "Processing text: The legal review concluded with no significant issues identified....\n",
            "Processing text: The attorney provided exceptional support during the trial....\n",
            "Processing text: The settlement negotiations broke down due to irreconcilable differences....\n",
            "Processing text: The new law ensures equal rights for all citizens without bias....\n",
            "Processing text: The dispute resolution process was delayed indefinitely....\n",
            "Processing text: The legal document was clear and well-structured for all parties....\n",
            "Processing text: The client was dissatisfied with the prolonged court proceedings....\n",
            "Processing text: The arbitration panel upheld the original agreement terms....\n",
            "Processing text: The lawyer’s strategy led to a successful case outcome....\n",
            "Processing text: The appeal was rejected due to insufficient evidence....\n",
            "Processing text: The policy update was met with widespread approval in the industry....\n",
            "Processing text: The case file contained several procedural errors....\n",
            "Processing text: The mediation session resulted in a fair compromise....\n",
            "Processing text: The judge praised the defendant’s compliance with regulations....\n",
            "Processing text: The contract dispute escalated to a costly lawsuit....\n",
            "Processing text: The legal advice was impartial and well-reasoned....\n",
            "Processing text: The client celebrated the favorable verdict after months of effort....\n",
            "Processing text: The regulatory changes imposed heavy fines on the company....\n",
            "Processing text: The court hearing proceeded smoothly with no objections....\n",
            "Processing text: The defense attorney’s argument was compelling and convincing....\n",
            "Processing text: The merger agreement faced significant legal challenges....\n",
            "Processing text: The legal team ensured transparency throughout the process....\n",
            "Processing text: The ruling strengthened the rights of small business owners....\n",
            "Results saved to predicted_output.csv\n",
            "\n",
            "Sentiment Analysis Table:\n",
            "                                                                Statement Predicted Expected\n",
            "   The court ruled in favor of the plaintiff, awarding full compensation.  Positive Positive\n",
            "    The contract terms were deemed unfair and unenforceable by the judge.  Negative Negative\n",
            "        The legal review concluded with no significant issues identified.   Neutral  Neutral\n",
            "              The attorney provided exceptional support during the trial.  Positive Positive\n",
            "The settlement negotiations broke down due to irreconcilable differences.  Negative Negative\n",
            "          The new law ensures equal rights for all citizens without bias.  Positive Positive\n",
            "                 The dispute resolution process was delayed indefinitely.  Negative Negative\n",
            "        The legal document was clear and well-structured for all parties.  Positive  Neutral\n",
            "        The client was dissatisfied with the prolonged court proceedings.  Negative Negative\n",
            "               The arbitration panel upheld the original agreement terms.   Neutral  Neutral\n",
            "                  The lawyer’s strategy led to a successful case outcome.  Positive Positive\n",
            "                    The appeal was rejected due to insufficient evidence.  Negative Negative\n",
            "      The policy update was met with widespread approval in the industry.  Positive Positive\n",
            "                       The case file contained several procedural errors.  Negative Negative\n",
            "                     The mediation session resulted in a fair compromise.  Positive  Neutral\n",
            "           The judge praised the defendant’s compliance with regulations.  Positive Positive\n",
            "                      The contract dispute escalated to a costly lawsuit.  Negative Negative\n",
            "                        The legal advice was impartial and well-reasoned.  Positive  Neutral\n",
            "      The client celebrated the favorable verdict after months of effort.  Positive Positive\n",
            "               The regulatory changes imposed heavy fines on the company.  Negative Negative\n",
            "                 The court hearing proceeded smoothly with no objections.  Positive  Neutral\n",
            "           The defense attorney’s argument was compelling and convincing.  Positive Positive\n",
            "                 The merger agreement faced significant legal challenges.   Neutral Negative\n",
            "              The legal team ensured transparency throughout the process.  Positive  Neutral\n",
            "             The ruling strengthened the rights of small business owners.  Positive Positive\n",
            "Verified: Output file exists at predicted_output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8de21a2c"
      },
      "source": [
        "## Clean up dummy data logic\n",
        "\n",
        "### Subtask:\n",
        "Remove or comment out the code related to creating dummy data and handling the `--dummy` argument as it will no longer be the primary method for getting input.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d0c97a0"
      },
      "source": [
        "**Reasoning**:\n",
        "Remove the argparse logic and the dummy data creation code to rely solely on the uploaded file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e7e0036",
        "outputId": "a6aab5e5-79d1-40c5-9852-4248344c4e03"
      },
      "source": [
        "# Load and process data\n",
        "try:\n",
        "    # The uploaded_file_path is available from the previous cell\n",
        "    print(f\"Attempting to load {uploaded_file_path}\")\n",
        "    # Modify pd.read_csv to use the uploaded_file_path\n",
        "    data = pd.read_csv(uploaded_file_path, encoding='utf-8', on_bad_lines='warn')\n",
        "    print(f\"Raw columns detected: {data.columns.tolist()}\")\n",
        "    if data.empty:\n",
        "        raise ValueError(\"Input CSV is empty.\")\n",
        "\n",
        "    # Adjust if \"Text,Sentiment\" is a single column\n",
        "    if \"Text,Sentiment\" in data.columns and (\"Text\" not in data.columns or \"Sentiment\" not in data.columns):\n",
        "        print(\"Splitting 'Text,Sentiment' column...\")\n",
        "        data[[\"Text\", \"Sentiment\"]] = data[\"Text,Sentiment\"].str.split(\",\", n=1, expand=True)\n",
        "    elif \"Text\" not in data.columns or \"Sentiment\" not in data.columns:\n",
        "        raise ValueError(\"CSV must have 'Text' and 'Sentiment' columns or a 'Text,Sentiment' column to split.\")\n",
        "\n",
        "    data[\"Text\"] = data[\"Text\"].astype(str).str.strip().str.strip('\"')\n",
        "    data[\"Sentiment\"] = data[\"Sentiment\"].astype(str).str.strip().str.strip('\"')\n",
        "    texts = data[\"Text\"].tolist()\n",
        "    expected_sentiments = data[\"Sentiment\"].tolist()\n",
        "    print(f\"Loaded {len(texts)} rows from CSV: {texts[:5]}...\")  # Show first five for better debug\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or processing CSV: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Set up FLAN-T5 model\n",
        "try:\n",
        "    model_name = \"google/flan-t5-base\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda:0\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    sys.exit(1)\n",
        "\n",
        "# Sentiment classification function\n",
        "def get_sentiment(text):\n",
        "    print(f\"Processing text: {text[:100]}...\") # Print first 100 characters of text\n",
        "    prompt = f\"Classify the sentiment of this legal text as Positive, Negative, or Neutral. Examples: 'The case was resolved favorably.' → Positive, 'The contract terms are unfair.' → Negative, 'The summary is neutral.' → Neutral. Text: {text}\\nSentiment:\"\n",
        "    try:\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=512, truncation=True).to(\"cuda:0\")\n",
        "        outputs = model.generate(**inputs, max_length=10, num_return_sequences=1)\n",
        "        sentiment = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
        "        if \"Positive\" in sentiment:\n",
        "            return \"Positive\"\n",
        "        elif \"Negative\" in sentiment:\n",
        "            return \"Negative\"\n",
        "        elif \"Neutral\" in sentiment:\n",
        "            return \"Neutral\"\n",
        "        else:\n",
        "            return \"Neutral\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing text '{text[:100]}...': {e}\") # Print error with truncated text\n",
        "        return \"Neutral\"\n",
        "\n",
        "\n",
        "# Apply to all texts\n",
        "sentiments = [get_sentiment(text) for text in texts]\n",
        "\n",
        "# Create and save output\n",
        "output_df = pd.DataFrame({\"Statement\": texts, \"Predicted\": sentiments, \"Expected\": expected_sentiments})\n",
        "\n",
        "# Define the output file path\n",
        "output_csv_path = \"predicted_output.csv\"\n",
        "\n",
        "# Create the directory for the output CSV if it doesn't exist\n",
        "output_dir = os.path.dirname(output_csv_path)\n",
        "if output_dir and not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "try:\n",
        "    output_df.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Results saved to {output_csv_path}\")\n",
        "    # Display the output table\n",
        "    print(\"\\nSentiment Analysis Table:\")\n",
        "    print(output_df.to_string(index=False))\n",
        "    # Verify file creation\n",
        "    if os.path.exists(output_csv_path):\n",
        "        print(f\"Verified: Output file exists at {output_csv_path}\")\n",
        "    else:\n",
        "        print(f\"Warning: Output file was not created at {output_csv_path}\")\n",
        "except PermissionError:\n",
        "    print(f\"Error: Permission denied when saving to {output_csv_path}. Check directory permissions.\")\n",
        "    sys.exit(1)\n",
        "except Exception as e:\n",
        "    print(f\"Error saving output: {e}\")\n",
        "    sys.exit(1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load custom_legal_dataset (1).csv\n",
            "Raw columns detected: ['Text', 'Sentiment']\n",
            "Loaded 25 rows from CSV: ['The court ruled in favor of the plaintiff, awarding full compensation.', 'The contract terms were deemed unfair and unenforceable by the judge.', 'The legal review concluded with no significant issues identified.', 'The attorney provided exceptional support during the trial.', 'The settlement negotiations broke down due to irreconcilable differences.']...\n",
            "Processing text: The court ruled in favor of the plaintiff, awarding full compensation....\n",
            "Processing text: The contract terms were deemed unfair and unenforceable by the judge....\n",
            "Processing text: The legal review concluded with no significant issues identified....\n",
            "Processing text: The attorney provided exceptional support during the trial....\n",
            "Processing text: The settlement negotiations broke down due to irreconcilable differences....\n",
            "Processing text: The new law ensures equal rights for all citizens without bias....\n",
            "Processing text: The dispute resolution process was delayed indefinitely....\n",
            "Processing text: The legal document was clear and well-structured for all parties....\n",
            "Processing text: The client was dissatisfied with the prolonged court proceedings....\n",
            "Processing text: The arbitration panel upheld the original agreement terms....\n",
            "Processing text: The lawyer’s strategy led to a successful case outcome....\n",
            "Processing text: The appeal was rejected due to insufficient evidence....\n",
            "Processing text: The policy update was met with widespread approval in the industry....\n",
            "Processing text: The case file contained several procedural errors....\n",
            "Processing text: The mediation session resulted in a fair compromise....\n",
            "Processing text: The judge praised the defendant’s compliance with regulations....\n",
            "Processing text: The contract dispute escalated to a costly lawsuit....\n",
            "Processing text: The legal advice was impartial and well-reasoned....\n",
            "Processing text: The client celebrated the favorable verdict after months of effort....\n",
            "Processing text: The regulatory changes imposed heavy fines on the company....\n",
            "Processing text: The court hearing proceeded smoothly with no objections....\n",
            "Processing text: The defense attorney’s argument was compelling and convincing....\n",
            "Processing text: The merger agreement faced significant legal challenges....\n",
            "Processing text: The legal team ensured transparency throughout the process....\n",
            "Processing text: The ruling strengthened the rights of small business owners....\n",
            "Results saved to predicted_output.csv\n",
            "\n",
            "Sentiment Analysis Table:\n",
            "                                                                Statement Predicted Expected\n",
            "   The court ruled in favor of the plaintiff, awarding full compensation.  Positive Positive\n",
            "    The contract terms were deemed unfair and unenforceable by the judge.  Negative Negative\n",
            "        The legal review concluded with no significant issues identified.   Neutral  Neutral\n",
            "              The attorney provided exceptional support during the trial.  Positive Positive\n",
            "The settlement negotiations broke down due to irreconcilable differences.  Negative Negative\n",
            "          The new law ensures equal rights for all citizens without bias.  Positive Positive\n",
            "                 The dispute resolution process was delayed indefinitely.  Negative Negative\n",
            "        The legal document was clear and well-structured for all parties.  Positive  Neutral\n",
            "        The client was dissatisfied with the prolonged court proceedings.  Negative Negative\n",
            "               The arbitration panel upheld the original agreement terms.   Neutral  Neutral\n",
            "                  The lawyer’s strategy led to a successful case outcome.  Positive Positive\n",
            "                    The appeal was rejected due to insufficient evidence.  Negative Negative\n",
            "      The policy update was met with widespread approval in the industry.  Positive Positive\n",
            "                       The case file contained several procedural errors.  Negative Negative\n",
            "                     The mediation session resulted in a fair compromise.  Positive  Neutral\n",
            "           The judge praised the defendant’s compliance with regulations.  Positive Positive\n",
            "                      The contract dispute escalated to a costly lawsuit.  Negative Negative\n",
            "                        The legal advice was impartial and well-reasoned.  Positive  Neutral\n",
            "      The client celebrated the favorable verdict after months of effort.  Positive Positive\n",
            "               The regulatory changes imposed heavy fines on the company.  Negative Negative\n",
            "                 The court hearing proceeded smoothly with no objections.  Positive  Neutral\n",
            "           The defense attorney’s argument was compelling and convincing.  Positive Positive\n",
            "                 The merger agreement faced significant legal challenges.   Neutral Negative\n",
            "              The legal team ensured transparency throughout the process.  Positive  Neutral\n",
            "             The ruling strengthened the rights of small business owners.  Positive Positive\n",
            "Verified: Output file exists at predicted_output.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97606d62"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The code was successfully modified to allow users to upload a CSV file for sentiment analysis using `google.colab.files.upload()`.\n",
        "*   The data loading process was updated to read from the uploaded file path.\n",
        "*   The code now successfully identifies and loads data from CSVs with separate 'Text' and 'Sentiment' columns or a combined 'Text,Sentiment' column.\n",
        "*   The sentiment analysis is performed using the FLAN-T5 model on the 'Text' column of the uploaded data.\n",
        "*   The results, including the original text, predicted sentiment, and expected sentiment, are saved to a new CSV file named \"predicted\\_output.csv\".\n",
        "*   The dummy data generation logic and the use of `argparse` for handling dummy data were successfully removed, ensuring the code relies solely on the uploaded file for input.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The current implementation assumes the uploaded CSV has either 'Text' and 'Sentiment' columns or a 'Text,Sentiment' column; adding more robust error handling or input validation for different column names could improve usability.\n",
        "*   Consider adding a feature to allow the user to specify the output file name instead of hardcoding \"predicted\\_output.csv\".\n"
      ]
    }
  ]
}